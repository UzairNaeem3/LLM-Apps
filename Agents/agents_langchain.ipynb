{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ccd87d8-5063-40a4-80e9-036c4bd07442",
   "metadata": {},
   "source": [
    "## What is an agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d8af59-b272-4de1-aeb5-315fbfee0cc0",
   "metadata": {},
   "source": [
    "__Definition:__ The key behind agents is giving LLM's the possibility of using tools in their workflow. This is where langchain departs from the popular chatgpt implementation and we can start to get a glimpse of what it offers us as builders. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e87bc-747d-4909-aedc-6052d3126acb",
   "metadata": {},
   "source": [
    "The official definition of agents is the following:\n",
    "- Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e3038e-35fd-4201-b5c2-a3dcc0db52fd",
   "metadata": {},
   "source": [
    "### Agents and Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17bceda-43b3-44b3-97cd-f9b7c423ac3a",
   "metadata": {},
   "source": [
    "To use agents, we require three things:\n",
    "- A base LLM,\n",
    "- A tool that we will be interacting with,\n",
    "- An agent to control the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b370d5-d09c-49cf-8570-dae5edaa3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let’s start by initializing our base LLM.\n",
    "from langchain import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    openai_api_key=\"\",\n",
    "    temperature=0,\n",
    "    model_name=\"text-davinci-003\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc13a56f-2d38-4e46-bb03-818e948669f9",
   "metadata": {},
   "source": [
    "When initializing tools, we either create a custom tool or load a prebuilt tool. In either case, the “tool” is a __utility chain__ given a tool __name__ and __description__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ecd9b-75b6-4f2e-87ca-884b333a47c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, we could create a new calculator tool from the existing llm_math chain:\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.agents import Tool\n",
    "\n",
    "llm_math = LLMMathChain(llm=llm)\n",
    "\n",
    "# initialize the math tool\n",
    "math_tool = Tool(\n",
    "    name='Calculator',\n",
    "    func=llm_math.run,\n",
    "    description='Useful for when you need to answer questions about math.'\n",
    ")\n",
    "# when giving tools to LLM, we must pass as list of tools\n",
    "tools = [math_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8d88a81-d0ec-4acc-9b30-0091d25b3839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Calculator', 'Useful for when you need to answer questions about math.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].name, tools[0].description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c315e8e-6b1c-4922-9bd7-aa9efc9c582c",
   "metadata": {},
   "source": [
    "We must follow this process when using custom tools. However, a prebuilt __llm_math__ tool does the same thing. So, we could do the same as above like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "947d10ce-c45d-484b-a840-8f043c4744d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    ['llm-math'],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76d8f448-c775-49bc-a15a-e0428fdb7db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Calculator', 'Useful for when you need to answer questions about math.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].name, tools[0].description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14283002-8764-40f3-b92e-782d667d965e",
   "metadata": {},
   "source": [
    "We now have the LLM and tools but no agent. To initialize a simple agent, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce40a286-35ff-4272-bc6b-ece3060e0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a730eae5-a7cf-410b-9413-8c41334e6e0b",
   "metadata": {},
   "source": [
    "As the name suggests, we will use this agent to perform __'zero shot'__ tasks on the input. That means that we will not have several, interdependent interactions but only one. In other words, this agent will have no memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d843a-7072-4e3b-b81b-24f983e92b6d",
   "metadata": {},
   "source": [
    "Now we are ready to initialize the agent! We will use verbose in True so we can see what is our agent's 'thinking' process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb4258-3fc9-4fed-abc1-dfc462afab29",
   "metadata": {},
   "source": [
    "__Important Note:__ When interacting with agents it is really important to set the max_iterations parameters because agents can get stuck in infinite loops that consume plenty of tokens. The default value is 15 to allow for many tools and complex reasoning but for most applications you should keep it much lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d0a5c7e-2cba-44c1-902e-1e78614c5beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to calculate this expression\n",
      "Action: Calculator\n",
      "Action Input: (4.5*2.1)^2.2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 139.94261298333066\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 139.94261298333066\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is (4.5*2.1)^2.2?', 'output': '139.94261298333066'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With our agent initialized, we can begin using it. Let’s try a few prompts and see how the agent responds.\n",
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c02cd230-4816-4652-ad65-3526eb860bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For verification: 139.94261298333066\n"
     ]
    }
   ],
   "source": [
    "print(\"For verification:\", (4.5*2.1)**2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c83ab823-ac69-4967-bf7f-7475f199c9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to figure out how many apples are in the boxes\n",
      "Action: Calculator\n",
      "Action Input: 8 * 2.5\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 20.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to add the apples Mary has to the apples in the boxes\n",
      "Action: Calculator\n",
      "Action Input: 4 + 20.0\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 24.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: We have 24 apples.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'if Mary has four apples and Giorgio brings two and a half apple boxes (apple box contains eight apples), how many apples do we have?',\n",
       " 'output': 'We have 24 apples.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try another\n",
    "zero_shot_agent(\"if Mary has four apples and Giorgio brings two and a half apple \"\n",
    "                \"boxes (apple box contains eight apples), how many apples do we \"\n",
    "                \"have?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7ec0b-432f-4382-a699-4b361f6ecfd6",
   "metadata": {},
   "source": [
    "Looks great! But what if we decide to ask a non-math question? What if we ask an easy common knowledge question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a4890af-7e83-4cef-ac92-26b6fb957619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to look up the answer\n",
      "Action: Look up\n",
      "Action Input: Capital of Pakistan\u001b[0m\n",
      "Observation: Look up is not a valid tool, try one of [Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the answer online\n",
      "Action: Search\n",
      "Action Input: Capital of Pakistan\u001b[0m\n",
      "Observation: Search is not a valid tool, try one of [Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the answer in a database\n",
      "Action: Database\n",
      "Action Input: Capital of Pakistan\u001b[0m\n",
      "Observation: Database is not a valid tool, try one of [Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the capital of Pakistan?',\n",
       " 'output': 'Agent stopped due to iteration limit or time limit.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"what is the capital of Pakistan?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36b36bf-b5af-41eb-b9aa-493e59e5688c",
   "metadata": {},
   "source": [
    "We run into an error. The problem here is that the agent keeps trying to use a tool. Yet, our agent contains only one tool — the calculator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af861cf-6fd8-4d02-a683-188dad1276b1",
   "metadata": {},
   "source": [
    "Fortunately, we can fix this problem by giving our agent more tools! Let’s add a plain and simple LLM tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32094472-7200-49a3-b7f0-206d2bd33888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"{query}\"\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# initialize the LLM tool\n",
    "llm_tool = Tool(\n",
    "    name='Language Model',\n",
    "    func=llm_chain.run,\n",
    "    description='use this tool for general purpose queries and logic'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb24b970-7f8d-45af-9a20-60277f9f53f2",
   "metadata": {},
   "source": [
    "With this, we have a new general-purpose LLM tool. All we do is add it to the tools list and reinitialize the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7113cf4c-58ba-431a-a753-81f886b465d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.append(llm_tool)\n",
    "\n",
    "# reinitialize the agent\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd72eb7-79bc-4088-9ed8-edd432bea3a1",
   "metadata": {},
   "source": [
    "Now we can ask the agent questions about both math and general knowledge. Let’s try the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f6428b1-d430-49e0-a5f6-f9705a88bf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the capital of Pakistan\n",
      "Action: Language Model\n",
      "Action Input: What is the capital of Pakistan?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "\n",
      "The capital of Pakistan is Islamabad.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The capital of Pakistan is Islamabad.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the capital of Pakistan?',\n",
       " 'output': 'The capital of Pakistan is Islamabad.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"what is the capital of Pakistan?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f6e30b-3ff4-4231-82bb-a1cbb1e8992e",
   "metadata": {},
   "source": [
    "__Now we get the correct answer! We can ask the first question:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d005660-36ab-4dfc-9d22-abb01c390ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to calculate this expression\n",
      "Action: Calculator\n",
      "Action Input: (4.5*2.1)^2.2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 139.94261298333066\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 139.94261298333066\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is (4.5*2.1)^2.2?', 'output': '139.94261298333066'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b5a7f-d60e-41e3-96e2-af6789b899b0",
   "metadata": {},
   "source": [
    "And the agent understands it must refer to the calculator tool, which it does — giving us the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc911d2-8abf-4332-a2fe-e8051036926e",
   "metadata": {},
   "source": [
    "### Creating Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08517973-0139-4165-aa25-e5a48f03d14c",
   "metadata": {},
   "source": [
    "We will use the agents to interact with a small sample database of stocks. We will now dive into the details because this is just a dummy tool we will build for illustrative purposes. Let's create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5bdcd24-9f11-4a8f-821c-57a5501d1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData\n",
    "\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ab23cf8-ddb6-44d2-961c-815fa7d656c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String, Table, Date, Float\n",
    "\n",
    "stocks = Table(\n",
    "    \"stocks\",\n",
    "    metadata_obj,\n",
    "    Column(\"obs_id\", Integer, primary_key=True),\n",
    "    Column(\"stock_ticker\", String(4), nullable=False),\n",
    "    Column(\"price\", Float, nullable=False),\n",
    "    Column(\"date\", Date, nullable=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66ff4053-94cb-44a2-b8b1-9e9e5392971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc7b7682-d30b-46c3-80a6-2aeec7319847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "observations = [\n",
    "    [1, 'ABC', 200, datetime(2023, 1, 1)],\n",
    "    [2, 'ABC', 208, datetime(2023, 1, 2)],\n",
    "    [3, 'ABC', 232, datetime(2023, 1, 3)],\n",
    "    [4, 'ABC', 225, datetime(2023, 1, 4)],\n",
    "    [5, 'ABC', 226, datetime(2023, 1, 5)],\n",
    "    [6, 'XYZ', 810, datetime(2023, 1, 1)],\n",
    "    [7, 'XYZ', 803, datetime(2023, 1, 2)],\n",
    "    [8, 'XYZ', 798, datetime(2023, 1, 3)],\n",
    "    [9, 'XYZ', 795, datetime(2023, 1, 4)],\n",
    "    [10, 'XYZ', 791, datetime(2023, 1, 5)],\n",
    "]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a7f3208-25d7-43c0-93c1-37420c4bde22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "def insert_obs(obs):\n",
    "    stmt = insert(stocks).values(\n",
    "    obs_id=obs[0],\n",
    "    stock_ticker=obs[1],\n",
    "    price=obs[2],\n",
    "    date=obs[3]\n",
    "    )\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3bafb51-8446-4a09-845d-3aa0b742601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obs in observations:\n",
    "    insert_obs(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "003f34dc-d88e-46e1-8a29-e665c5b278fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "db = SQLDatabase(engine)\n",
    "sql_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6870377-575d-4b0b-9bcb-26e2a0f46a23",
   "metadata": {},
   "source": [
    "## Agent types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e6766a-ed76-4d8b-9db4-fa9509f6cff6",
   "metadata": {},
   "source": [
    "In this section we will review several agents and see how they 'think' and what they can do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce5542-8a39-415b-9beb-16f966838c57",
   "metadata": {},
   "source": [
    "### Agent type1: Zero Shot React"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8947b0b7-515f-4995-b0a6-f4163439c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    max_iterations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c14a357-c6e0-4b4b-9e6d-e814e5f5e6b0",
   "metadata": {},
   "source": [
    "Let's see our newly created agent in action! We will ask it a question that involves a math operation over the stock prices.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7d8d2a3-cd18-4cd1-a390-b3919fca00e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
      "Action Input: \u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mstocks\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should query the schema of the stocks table\n",
      "Action: sql_db_schema\n",
      "Action Input: stocks\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE stocks (\n",
      "\tobs_id INTEGER NOT NULL, \n",
      "\tstock_ticker VARCHAR(4) NOT NULL, \n",
      "\tprice FLOAT NOT NULL, \n",
      "\tdate DATE NOT NULL, \n",
      "\tPRIMARY KEY (obs_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from stocks table:\n",
      "obs_id\tstock_ticker\tprice\tdate\n",
      "1\tABC\t200.0\t2023-01-01\n",
      "2\tABC\t208.0\t2023-01-02\n",
      "3\tABC\t232.0\t2023-01-03\n",
      "*/\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should query the ratio between the stock prices for 'ABC' and 'XYZ' in January 3rd and the ratio between the same stock prices in January the 4th\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT (SELECT price FROM stocks WHERE stock_ticker = 'ABC' AND date = '2023-01-03') / (SELECT price FROM stocks WHERE stock_ticker = 'XYZ' AND date = '2023-01-03') / (SELECT price FROM stocks WHERE stock_ticker = 'ABC' AND date = '2023-01-04') / (SELECT price FROM stocks WHERE stock_ticker = 'XYZ' AND date = '2023-01-04')\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[(1.6253071532780239e-06,)]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor(\n",
    "    \"What is the multiplication of the ratio between stock \" +\n",
    "    \"prices for 'ABC' and 'XYZ' in January 3rd and the ratio \" +\n",
    "    \"between the same stock prices in January the 4th?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8224cb04-4176-49e9-8317-2dcdddb4762a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an agent designed to interact with a SQL database.\n",
      "Given an input question, create a syntactically correct sqlite query to run, then look at the results of the query and return the answer.\n",
      "Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 10 results.\n",
      "You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n",
      "You have access to tools for interacting with the database.\n",
      "Only use the below tools. Only use the information returned by the below tools to construct your final answer.\n",
      "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
      "\n",
      "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
      "\n",
      "If the question does not seem related to the database, just return \"I don't know\" as the answer.\n",
      "\n",
      "\n",
      "sql_db_query: Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\n",
      "sql_db_schema: Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: 'table1, table2, table3'\n",
      "sql_db_list_tables: Input is an empty string, output is a comma separated list of tables in the database.\n",
      "sql_db_query_checker: Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [sql_db_query, sql_db_schema, sql_db_list_tables, sql_db_query_checker]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought: I should look at the tables in the database to see what I can query.  Then I should query the schema of the most relevant tables.\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "# let's see what the prompt is here:\n",
    "print(agent_executor.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb6916-3cac-4956-968c-ad4ba68f9ce7",
   "metadata": {},
   "source": [
    "Finally, let's pay attention to the __'agent_scratchpad'__. What is that? Well, that is where we will be appending every thought or action that the agent has already performed. In this way, at each point in time, the agent will know what it has found out and will be able to continue its thought process. In other words, after using a tool it adds its thoughts and observations to the scratchpad and picks up from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d22ade4-ac59-46fc-89f1-f70f052e67ac",
   "metadata": {},
   "source": [
    "### Agent type2: Conversational React"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a46b22e-b27a-4da7-b9f9-236289e4fed5",
   "metadata": {},
   "source": [
    "The zero shot agent is really interesting but, as we said before, it has no memory. What if we want an assistant that remembers things we have talked about and can also reason about them and use tools? For that we have the conversational react agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d8d156-7a71-4994-85eb-ae258be877aa",
   "metadata": {},
   "source": [
    "To initialize the agent, we first need to initialize the memory we’d like to use. We will use the simple __ConversationBufferMemory__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e26a300-452b-438c-92b0-8a704a0a5cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c984ee0-8666-447b-b559-e1b9994241dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the math tool in this example and load it as below:\n",
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    [\"llm-math\"],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39f2f714-1804-49ea-acd5-68380aa4000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "conversational_agent = initialize_agent(\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07c94b09-f208-4f43-9dce-72bd13b35d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Calculator\n",
      "Action Input: 10,000, 8%, 5 years\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 14693.280768000006\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: The result of an investment of $10,000 growing at 8% annually for 5 years with compound interest is $14,693.28.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = conversational_agent(\n",
    "    \"What's the result of an investment of $10,000 growing at 8% annually for 5 years with compound interest?\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a715fa8-c172-472b-98ee-44eb21e47a09",
   "metadata": {},
   "source": [
    "As we can see, the prompt is similar but it includes a great prelude of instructions that make it an effective assistant as well + a spot for including the chat history from the memory component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "260c618a-2fc1-4c4d-b13c-4c4122df7976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "TOOLS:\n",
      "------\n",
      "\n",
      "Assistant has access to the following tools:\n",
      "\n",
      "> Calculator: Useful for when you need to answer questions about math.\n",
      "\n",
      "To use a tool, please use the following format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: the action to take, should be one of [Calculator]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: [your response here]\n",
      "```\n",
      "\n",
      "Begin!\n",
      "\n",
      "Previous conversation history:\n",
      "{chat_history}\n",
      "\n",
      "New input: {input}\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(conversational_agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01ed2a95-7997-44c9-9f73-f45022e3414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Calculator\n",
      "Action Input: 15000, 8%, 5 years, compound interest\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 22039.92115200001\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: If we start with $15,000 instead and follow the same 8% annual growth for 5 years with compound interest, we would have $22,039.92, which is $7,346.64 more than the previous scenario.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Let's see what happens if we try to answer the question that is related to the previous one:\n",
    "result = conversational_agent(\n",
    "    \"If we start with $15,000 instead and follow the same 8% annual growth for 5 years with compound interest, how much more would we have compared to the previous scenario?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8614e8-c58b-4545-a05a-bbf9e6cbafeb",
   "metadata": {},
   "source": [
    "### Agent type3: Self Ask with Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bbf9f5-8900-44cf-9fee-f0dd27992769",
   "metadata": {},
   "source": [
    "This is the first-choice agent to use when using LLM's to extract information with a search engine. The agent will ask follow-up questions and use the search functionality to get intermediate answers that help it get to a final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9c4558e-0be6-40a6-bfcf-11aefff75d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "# Creating a Google Search Tool using the SerpAPIWrapper (SerpApi is a real-time API to access Google search results) which requires an API key (you can generate it on their website)\n",
    "search = SerpAPIWrapper(serpapi_api_key='111552fa19709a6e3919da9e05cea8718dcc53ab73bc8dcc503cd8e7c6b06bc5')\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description='google search'\n",
    "    )\n",
    "]\n",
    "\n",
    "self_ask_with_search = initialize_agent(tools, llm, agent=\"self-ask-with-search\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec108133-47cf-4c3b-b8dc-59d70a142c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali\n",
      "\n",
      "Question: When was the founder of craigslist born?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the founder of craigslist?\n",
      "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
      "Follow up: When was Craig Newmark born?\n",
      "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
      "So the final answer is: December 6, 1952\n",
      "\n",
      "Question: Who was the maternal grandfather of George Washington?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball\n",
      "\n",
      "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who is the director of Jaws?\n",
      "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
      "Follow up: Where is Steven Spielberg from?\n",
      "Intermediate answer: The United States.\n",
      "Follow up: Who is the director of Casino Royale?\n",
      "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
      "Follow up: Where is Martin Campbell from?\n",
      "Intermediate answer: New Zealand.\n",
      "So the final answer is: No\n",
      "\n",
      "Question: {input}\n",
      "Are followup questions needed here:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(self_ask_with_search.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a18910a-2e76-4bf9-b4a3-262da7e3dd58",
   "metadata": {},
   "source": [
    "As we can see, the prompt is basically a series of many examples to show the LLM how to ask follow up questions to a search tool until it can get to the final answe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
